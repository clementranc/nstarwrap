{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting star profiles with a PSF model using DAOPHOT NSTAR-MCMC from Python\n",
    "\n",
    "Tutorial showing how to use NSTAR-MCMC from Python with a shared Fortran library.\n",
    "\n",
    "                  Version 1.0 - 8 April 2022\n",
    "                         Cl√©ment Ranc\n",
    "\n",
    "This code runs NSTAR-MCMC_PYWRAPPER, which has been developed from NSTAR-MCMC.<br>NSTAR-MCMC was initially developed by Sean Terry:\n",
    "\n",
    "- Code and documentation: https://github.com/skterry/daophot_mcmc\n",
    "- Article: Terry et al. 2021, AJ, 161, 54.\n",
    "\n",
    "NSTAR-MCMC is a modified version of the subroutine NSTAR of DAOPHOT-II developed by Peter Stetson:\n",
    "- Code: http://www.star.bris.ac.uk/~mbt/daophot/\n",
    "- Documentation: http://www.astro.wisc.edu/sirtf/daophot2.pdf\n",
    "\n",
    "The technical benefits of using the approach decribed in this tutorial include:\n",
    "\n",
    "- The possibility of using any Python package able to perform an MCMC. For example, we will use the widely recognized EMCEE package, running an _Affine Invariant_ algorithm (Foreman-Mackey et al. 2013, PASP, 125, 306).\n",
    "- The possibility of using your own customized MCMC algorithm.\n",
    "- The possibility of using any kind of optimization algorithm, such as the gradient method. We will show an example of using the Levenberg-Marquardt algorithm to find the best-fit model. \n",
    "- The ability to access the residuals (not only the chi-square) from within Python.\n",
    "- Priors on parameters can be added efforlessly, without any need for a new compilation.\n",
    "- The fitting process can be parallelized and run on many CPUs.\n",
    "- The back-and-forth of parameters between DAOPHOT and Python does not involve any file thanks to the shared python library I created, which speeds up the code.\n",
    "- The possibility of continuing an MCMC run you wish to be longer without any need to start again from the beginning.\n",
    "\n",
    "The physical models include:\n",
    "\n",
    "- a 2-star model,\n",
    "- a 3-star model,\n",
    "- a 4-star model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement and installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the instructions given in the [README.md](https://github.com/clementranc/nstarwrap/blob/main/README.md#installation-of-the-shared-library) file of the GitHub repository before studying this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real world example: a 2-star fit\n",
    "\n",
    "**Goal:** In this section, we show how to perform a 2-star fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clean directory includes:\n",
    "- An image, here `image.fits`\n",
    "- A PSF model produced by DAOPHOT, here `image.psf`\n",
    "- A list of stars of interest produced by DAOPHOT Group command, here `image.grp`\n",
    "\n",
    "We start by defining some basic variables, most of them are self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames\n",
    "image_file_name = 'image.fits'\n",
    "psf_model_file_name = 'image.psf'\n",
    "group_file_name = 'image.grp'\n",
    "\n",
    "# Needed parameters from the daophot.opt file or standard values.\n",
    "watch = 0.0\n",
    "fitrad = 9.8\n",
    "e1 = 0.75\n",
    "e2 = 5.0\n",
    "\n",
    "# Fitting box limits\n",
    "box_xmin, box_xmax, box_ymin, box_ymax = 1100, 1128, 1171, 1197\n",
    "\n",
    "# Initial position in the parameter space.\n",
    "# (x, y) position of star 1 (the brightest) and star 2 (the faintest),\n",
    "# Flux ratio between star 2 and star 1\n",
    "x1fg, y1fg = 1112.536, 1183.238\n",
    "x2fg, y2fg = 1112.368, 1189.931\n",
    "flux_ratio12_fg = 0.584269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to import the Fortran DAOPHOT shared library. MOAna is doing it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DAOPHOT tools of the Python package MOAna\n",
    "import nstarwrap.daotools as daotools\n",
    "\n",
    "# Import the shared library\n",
    "nstar_wrapper = daotools.NstarPythonWrapper(\n",
    "    image=image_file_name,\n",
    "    psf=psf_model_file_name,\n",
    "    group=group_file_name,\n",
    "    watch_daophot=watch, \n",
    "    fitrad_daophot=fitrad, \n",
    "    e1_daophot=e1,\n",
    "    e2_daophot=e2,\n",
    "    fitting_box=[box_xmin, box_xmax, box_ymin, box_ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the `ATTACH` command load the picture in memory and consists of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol, nrow = nstar_wrapper.attach()\n",
    "print(f'ncol = {ncol.value}, nrow={nrow.value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least-square fit and maximum likelihood estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to use a least-square algorithm to find the best-fitting model close to an initial position in the parameter space. For general purpose, let's use a Levenberg-Marquardt algorithm, less sensitive to local minima than a Newton method. We will use the implementation of the python package `scipy`. The Levenberg-Marquardt algorithm we use compute numerically the Jacobian matrix and minimize the cost function F(x):\n",
    "```python\n",
    "minimize F(x) = 0.5 * sum(rho(f_i(x)**2), i = 0, ..., m - 1)\n",
    "````\n",
    "where `f_i(x)` is the residual vector evaluated at the parameter space position (x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses nstar-mcmc to evaluate the residual vector\n",
    "def compute_residual_vector(x):\n",
    "    chi2, _ = nstar_wrapper.nstar_goodness_of_fit(x)\n",
    "    return nstar_wrapper.residuals\n",
    "\n",
    "# Define the initial conditions\n",
    "p0 = [x1fg, y1fg, x2fg, y2fg, flux_ratio12_fg]\n",
    "\n",
    "# Perform the fit\n",
    "from scipy.optimize import least_squares\n",
    "lsq_result = least_squares(compute_residual_vector, p0, method='lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of the fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Successful fit: {lsq_result['success']}\\n{lsq_result['message']}\")\n",
    "print(f\"Best-fit parameters:\\n   {lsq_result['x']}\")\n",
    "print(f\"Cost function of best-fit parameter: {lsq_result['cost']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image below displays the position of the two stars (magenta crosses)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"illustrations/Levenberg-Marquardt.png\" width=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC, prior and posterior distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the best-fit. Great! But a posterior distribution and error bars are much better!\n",
    "\n",
    "The MCMC performed below follows the same general approach as NSTAR-MCMC developed by Sean Terry, i.e., the badness-of-fit is computed exactly in the same way, and the fit is performed inside a fitting box. However, the constraints on the parameters are managed in a different way, adopting a Bayesian approch, i.e., using a prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log-prior\n",
    "def log_prior(x):\n",
    "    if (box_xmin < x[0] < box_xmax)\\\n",
    "        and (box_xmin < x[2] < box_xmax)\\\n",
    "        and (box_ymin < x[1] < box_ymax)\\\n",
    "        and (box_ymin < x[3] < box_ymax)\\\n",
    "        and (0 < x[4]):\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "# Define the log-probability function\n",
    "def log_probability(x):\n",
    "    x1, y1, x2, y2, fratio = x\n",
    "    \n",
    "    # Trick: we want star 1 to always be the brightest.\n",
    "    # TODO: remove this trick.\n",
    "    theta = x\n",
    "    if fratio > 1:\n",
    "        fratio = 1.0 / fratio\n",
    "        x1, x2, y1, y2 = x[2], x[0], x[3], x[1]\n",
    "        theta = [x[2], x[0], x[3], x[1], fratio]\n",
    "        \n",
    "    # Evaluate the log(prior)\n",
    "    lp = log_prior(theta)\n",
    "    if np.isinf(lp):\n",
    "        return lp, 0.0\n",
    "    \n",
    "    # Run NSTAR-MCMC to compute the chi-square and the total flux in the fitting box\n",
    "    chisq, total_flux = nstar_wrapper.nstar_goodness_of_fit(theta)\n",
    "    \n",
    "    return -0.5 * chisq + lp, total_flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's initialize the chains' position to a random position in the\n",
    "parameter space, close to the centroid positions we entered on top\n",
    "of this notebook. We also want all the chains to be inside the fitting\n",
    "box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of parameters you want to fit\n",
    "ndim = 5\n",
    "\n",
    "# We will use an Affine-invariant MCMC, implemented in EMCEE package.\n",
    "# It is very similar to the Differential-evolution MC, and deals very\n",
    "# well with the non linear posterior distributions.\n",
    "# Number of chains running in parallel (must be at least 2x the number\n",
    "# of parameters fitted and even.\n",
    "nwalkers = 10\n",
    "\n",
    "# Initial center of the 2 stars in the complex plane\n",
    "star1 = x1fg + 1j * y1fg\n",
    "star2 = x2fg + 1j * y2fg\n",
    "\n",
    "# We want to initialize the chains' position randomly around these \n",
    "# position, not to far. Let's use a Normal distribution in 2D around\n",
    "# the star centers. We ALSO want the stars to be inside the fitting\n",
    "# box intially.\n",
    "import numpy as np\n",
    "SEED = 42  # Random seed for reproductibility and debugging\n",
    "rng = np.random.default_rng(SEED)  # Initialize the random generator\n",
    "\n",
    "mu, sigma = 0, 1\n",
    "inside_box = [True]\n",
    "i = 0\n",
    "while(any(inside_box)):\n",
    "    p1 = star1 + rng.normal(mu, sigma, nwalkers) * np.exp(1j * rng.uniform(0, 2*np.pi, nwalkers))\n",
    "    p2 = star2 + rng.normal(mu, sigma, nwalkers) * np.exp(1j * rng.uniform(0, 2*np.pi, nwalkers))\n",
    "    p0 = np.array([p1.real, p1.imag, p2.real, p2.imag, \n",
    "                   flux_ratio12_fg + rng.normal(0, 0.3, nwalkers)]).T\n",
    "    inside_box = np.array([log_prior(a) for a in p0]) < 0\n",
    "    i = i+1\n",
    "    if i > 10:\n",
    "        print('Please change the box size of adapt the random choices to your box size.')\n",
    "        break\n",
    "\n",
    "# We replace the position in parameter space of the first chain by the\n",
    "# initial conditions we manually entered on top of this notebook.\n",
    "p0[0] = np.array([x1fg, y1fg, x2fg, y2fg, flux_ratio12_fg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to initialize the EnsembleSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will save the MCMC output in an HDF5 format (you can change that\n",
    "# if you wish), and we want to use the EMCEE Python package.\n",
    "filename = \"my_mcmc.h5\"\n",
    "\n",
    "import emcee\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "\n",
    "# Start a new MCMC, so we reset the backend\n",
    "backend.reset(nwalkers, ndim)\n",
    "\n",
    "# We will use blobs to carry the total flux (not fitted by EMCEE)\n",
    "nstar_params_name_light = [\"z0\"]\n",
    "dtype = [(a, np.float64) for a in nstar_params_name_light]\n",
    "\n",
    "# Initialization of the sampler with all the previous parameters\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, \n",
    "    blobs_dtype=dtype, backend=backend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start the MCMC run\n",
    "max_n = 1000  # Length of each MCMC chain\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "sampler.run_mcmc(p0, max_n, progress=True);\n",
    "end = time.time()\n",
    "run_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the correlations and the best fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic information about the MCMC run\n",
    "burnin = 0\n",
    "print(f'Autocorrelations:')\n",
    "print(f'   [Shape: {sampler.get_chain(discard=burnin, flat=False).shape}]')\n",
    "print(f'   {sampler.get_autocorr_time(quiet=True)}')\n",
    "samples = sampler.get_chain(discard=burnin, flat=True)\n",
    "log_prob_samples = sampler.get_log_prob(discard=burnin, flat=True)\n",
    "out = sampler.get_blobs(discard=burnin, flat=True)\n",
    "print(f'Zeropoint Mag: {nstar_wrapper.zpmag.value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "colnames = np.array(['x1', 'y1', 'x2', 'y2', 'flux_ratio'])\n",
    "mcmc_out = pd.DataFrame(samples, columns=colnames)\n",
    "mcmc_out['FTOTAL'] = out['z0']\n",
    "\n",
    "# Don't forget to take into account when flux ratio > 1.0\n",
    "# TODO: remove that!\n",
    "mask = mcmc_out['flux_ratio'] > 1\n",
    "mcmc_out.loc[mask, 'flux_ratio'] = 1 / mcmc_out.loc[mask, 'flux_ratio']\n",
    "x1 = mcmc_out.loc[mask, 'x2']\n",
    "y1 = mcmc_out.loc[mask, 'y2']\n",
    "x2 = mcmc_out.loc[mask, 'x1']\n",
    "y2 = mcmc_out.loc[mask, 'y1']\n",
    "mcmc_out.loc[mask, 'x1'] = x1\n",
    "mcmc_out.loc[mask, 'y1'] = y1\n",
    "mcmc_out.loc[mask, 'x2'] = x2\n",
    "mcmc_out.loc[mask, 'y2'] = y2\n",
    "mcmc_out['chi2'] = - 2.0 * log_prob_samples\n",
    "mcmc_out['dchi2'] = mcmc_out['chi2'] - np.min(mcmc_out['chi2'])\n",
    "\n",
    "display(mcmc_out[mcmc_out['chi2']==np.min(mcmc_out['chi2'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moana\n",
    "\n",
    "# Plot result of fitted parameters\n",
    "labels = ['x1', 'y1', 'x2', 'y2', 'flux_ratio']\n",
    "\n",
    "label_display = dict({'x1': r'x_1', 'x2': r'x_2', 'y1': r'y_1', 'y2': r'y_2',   \n",
    "    'flux_ratio': r'\\varphi_l/\\varphi_s'})\n",
    "\n",
    "mask = mcmc_out['dchi2'] < 100\n",
    "\n",
    "posterior = moana.SampledPosterior(mcmc_out[mask], labels=labels)\n",
    "fig, ax = posterior.corner_plot(credible_intervals=False, diagonal='chi2', \n",
    "    rotation=45, show_samples=True, labels=label_display);\n",
    "\n",
    "bf = mcmc_out[mcmc_out['chi2']==np.min(mcmc_out['chi2'])][labels].values[0]\n",
    "[ax[j][i].scatter(bf[i], bf[j], s=20, lw=0, marker='o', c='w') \n",
    " for i in range(len(labels)) for j in range(len(labels)) if i<j]\n",
    "\n",
    "#[ax[j][i].scatter(lsq_result.x[i], lsq_result.x[j], s=20, lw=0, marker='o', c='k') \n",
    "# for i in range(len(labels)) for j in range(len(labels)) if i<j]\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('correlation.png', bbox_inches='tight', dpi=72, pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a new \"correlation.png\" file that looks like this one:\n",
    "\n",
    "<div>\n",
    "<img src=\"illustrations/Correlation.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error-bar renormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Degrees of freedom: {nstar_wrapper.dof:d}')\n",
    "print(f\"Best chi-square: {np.min(mcmc_out['chi2']):.4f}\")\n",
    "print(f\"Suggested rescaling factor: {np.min(mcmc_out['chi2'])/nstar_wrapper.dof:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running again the MCMC, we will make some optimization and explore the potential of the python implementation of DAOPHOT. We do the following changes:\n",
    "- Add a chi-square rescaling factor to get more accurate error bars.\n",
    "- We will prepare the MCMC to run it on several CPU in parallel to spead up the code.\n",
    "- We will use a local binary file to store the FITS image to avoid running multiple times the ATTACH command when running the code in parallel. This is optional but highly recommended, as the code will be faster and more stable.\n",
    "\n",
    "To start this new adventure, please proceed to the tutorial 2. The tuto 2 is strongly recommended and seen as essential."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
